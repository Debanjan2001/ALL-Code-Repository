{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Contributor: Debanjan Saha\n",
        "\n",
        "Running on: Local Machine"
      ],
      "metadata": {
        "id": "zwwVJYlFUiDA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import product\n",
        "import nltk\n",
        "import math\n",
        "import random\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "asISCkXJflOT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cMavS6e5TdwO"
      },
      "outputs": [],
      "source": [
        "def load_dataset():\n",
        "    \"\"\"\n",
        "    Load dataset from the folder 'data'\n",
        "    \"\"\"\n",
        "    with open(\"./data/train.txt\", 'r') as f:\n",
        "        train_data = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    with open(\"./data/test.txt\", 'r') as f:\n",
        "        test_data = [line.strip() for line in f.readlines()]\n",
        "\n",
        "    return train_data, test_data"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, test_data = load_dataset()"
      ],
      "metadata": {
        "id": "fVOTfIHudBLO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### See sample sentences from Dataset"
      ],
      "metadata": {
        "id": "uyUme6CTUcXg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AxuZHwp2dM5N",
        "outputId": "fac7594c-56cd-4c9f-bee8-64a3a88186bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['liberty all star usa sets initial payout',\n",
              " 'we are being accused of not implementing this agreement',\n",
              " 'entregrowth closed at 135 dlrs and options at 55 cents',\n",
              " 'usda forecast south african 1986 87 corn exports at 210 mln tonnes vs 300 mln tonnes last month and 1985 86 exports at 275 mln tonnes vs 275 mln tonnes last month',\n",
              " 'norgolds issued capital will be 2405 mln shares of which 63 pct will be held by nbh after 89 mln are issued to shareholders to raise 196 mln dlrs it said']"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_data[:5]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rC4wZoYtdkAE",
        "outputId": "083a7f96-603e-4c65-dcbb-f267aa30c36f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['the company said each debenture is convertible into shares of businessland common stock at a conversion price of 2050 dlrs',\n",
              " 'sumita says he does not expect further dollar fall',\n",
              " 'the tin price is likely to rise to 20 ringgit a kilo this year because of the producers accord on export quotas and the reluctance of brokers and banks to sell the metal at lower prices a malaysian government bulletin said',\n",
              " 'march and the next two or three months will be a really critical period hernandez said',\n",
              " 'first union corp said shareholders of first north port bancorp of northport fla have approved a merger into first union for 40 dlrs per share or about 5100000 dlrs']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "len(train_data), len(test_data)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9_UfzzXx6Qc2",
        "outputId": "0b4ede8a-bbf4-4813-e0ba-07dc863540fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 15000)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "SOS_TOKEN = \"<s> \"\n",
        "EOS_TOKEN = \"</s>\"\n",
        "UNK_TOKEN = \"<UNK>\""
      ],
      "metadata": {
        "id": "CE0KKt0zU_dl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_sentence_tokens(sentences, n):\n",
        "    \"\"\"\n",
        "    Appends start of sentence token and end of sentence tokens at the starting and ending of the sentence\n",
        "    Based on the value of the n for n-gram model\n",
        "    \"\"\"\n",
        "    sents = []\n",
        "    sos = \"\"\n",
        "    if (n == 1) :\n",
        "        sos = SOS_TOKEN\n",
        "    else :\n",
        "        sos = SOS_TOKEN * (n-1)\n",
        "\n",
        "    for s in sentences:\n",
        "        cur_sent = f\"{sos}{s} {EOS_TOKEN}\" \n",
        "        sents.append(cur_sent)\n",
        "    return sents"
      ],
      "metadata": {
        "id": "-m67lsWdVXPJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Testing the function\n",
        "temp = add_sentence_tokens(train_data[:3], 3)\n",
        "temp[:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSeBEzTRXG-U",
        "outputId": "27a30abd-c41e-4344-e446-53cd92c5e471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s> <s> liberty all star usa sets initial payout </s>',\n",
              " '<s> <s> we are being accused of not implementing this agreement </s>',\n",
              " '<s> <s> entregrowth closed at 135 dlrs and options at 55 cents </s>']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def replace_single_occurrence(word_tokens):\n",
        "    \"\"\"\n",
        "    Replace tokens which appear only once in the corpus with <UNK> token\n",
        "    \"\"\"\n",
        "    freqCounter = nltk.FreqDist(word_tokens)\n",
        "    final_tokens = []\n",
        "    for token in word_tokens:\n",
        "        if freqCounter[token] > 1:\n",
        "            final_tokens.append(token)\n",
        "        else : \n",
        "            final_tokens.append(UNK_TOKEN)\n",
        "\n",
        "    return final_tokens  "
      ],
      "metadata": {
        "id": "cWSP18pjV8UM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing the function\n",
        "replace_single_occurrence(temp[0].split(\" \"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xKM0APixXtm4",
        "outputId": "a5af9b9f-d28e-4b61-a0de-fd4803aa320f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['<s>',\n",
              " '<s>',\n",
              " '<UNK>',\n",
              " '<UNK>',\n",
              " '<UNK>',\n",
              " '<UNK>',\n",
              " '<UNK>',\n",
              " '<UNK>',\n",
              " '<UNK>',\n",
              " '<UNK>']"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_text(sentences, n):\n",
        "    \"\"\"\n",
        "    Function to add SOS , EOS token and replace single occurence of tokens in corpus with UNK token\n",
        "    \"\"\"\n",
        "    sents = add_sentence_tokens(sentences, n)\n",
        "    word_tokens = \" \".join(sents).split(\" \")\n",
        "    final_word_tokens = replace_single_occurrence(word_tokens)\n",
        "    return final_word_tokens"
      ],
      "metadata": {
        "id": "5Z0LCteSYEDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class NGramLanguageModel:\n",
        "    \"\"\"\n",
        "    An n-gram language model trained on a given corpus.\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, train_data, n, laplace=1):\n",
        "        \"\"\"\n",
        "        Initiates the model with the training data and appropriate parameters\n",
        "        \"\"\"\n",
        "        self.n = n\n",
        "        self.laplace = laplace\n",
        "        self.word_tokens = process_text(train_data, n)\n",
        "        self.vocab = nltk.FreqDist(self.word_tokens)\n",
        "        self.model = self.create_model()\n",
        "\n",
        "        self.masks = list(product((0,1), repeat=n))\n",
        "        self.masks.reverse()\n",
        "\n",
        "\n",
        "    def laplace_smooth(self):\n",
        "        \"\"\"\n",
        "        Function to apply laplace smoothing on frequency distribution of the corpus\n",
        "        \"\"\"\n",
        "        vocab_size = len(self.vocab)\n",
        "\n",
        "        n_grams = nltk.ngrams(self.word_tokens, self.n)\n",
        "        n_vocab = nltk.FreqDist(n_grams)\n",
        "\n",
        "        m_grams = nltk.ngrams(self.word_tokens, self.n-1)\n",
        "        m_vocab = nltk.FreqDist(m_grams)\n",
        "\n",
        "        def get_laplace_smoothened_value(n_gram, n_count):\n",
        "            m_gram = n_gram[:-1]\n",
        "            m_count = m_vocab[m_gram]\n",
        "            value = (n_count + self.laplace) / (m_count + self.laplace * vocab_size)\n",
        "            return value \n",
        "        \n",
        "        prob_dist = {}\n",
        "        for n_gram, n_count in n_vocab.items():\n",
        "            prob_dist[n_gram] = get_laplace_smoothened_value(n_gram, n_count)\n",
        "\n",
        "        return prob_dist\n",
        "\n",
        "\n",
        "    def create_model(self):\n",
        "        \"\"\"\n",
        "        Builds probability distribution for the vocabulary of the training corpus based on value of n.\n",
        "        if n == 1(unigram), they are simple probabilities of tokens in the corpus otherwise laplace smoothing is applied\n",
        "        \"\"\"\n",
        "        prob_dist = {}\n",
        "        if self.n == 1:\n",
        "            num_word_tokens = len(self.word_tokens)\n",
        "            for unigram, word_count in self.vocab.items():\n",
        "                prob_dist[(unigram,)] = word_count / num_word_tokens\n",
        "        else:\n",
        "            prob_dist = self.laplace_smooth()\n",
        "        \n",
        "        return prob_dist\n",
        "\n",
        "\n",
        "    def handle_out_of_vocab_words(self, ngram):\n",
        "        \"\"\"\n",
        "        This function -\n",
        "        Handles out of vocab words during inference on test set.\n",
        "        Replaces some subset of tokens of the ngram with UNK token such that the model contains some entry corresponding to it \n",
        "        \"\"\"\n",
        "        \n",
        "        def generate_masked_word_tokens(ngram, bitmask):\n",
        "            final_ngram = []\n",
        "            for token, mask in zip(ngram, bitmask):\n",
        "                if mask == 1:\n",
        "                    final_ngram.append(token)\n",
        "                else:\n",
        "                    final_ngram.append(UNK_TOKEN)\n",
        "            \n",
        "            return tuple(final_ngram)\n",
        "        \n",
        "        if type(ngram) == str:\n",
        "            ngram = (ngram,)\n",
        "\n",
        "        for bitmask in self.masks:\n",
        "            combination = generate_masked_word_tokens(ngram, bitmask)\n",
        "            if combination in self.model:\n",
        "                return combination\n",
        "\n",
        "\n",
        "    def calculate_perplexity(self, test_data):\n",
        "        \"\"\"\n",
        "        Calculates the perplexity of the model on a test corpus.\n",
        "        \"\"\"\n",
        "\n",
        "        test_word_tokens = process_text(test_data, self.n)\n",
        "        num_test_word_tokens = len(test_word_tokens)\n",
        "\n",
        "        test_ngrams = nltk.ngrams(test_word_tokens, self.n)\n",
        "\n",
        "        known_ngrams_list = []\n",
        "        for ngram in test_ngrams:\n",
        "            known_ngrams_list.append(self.handle_out_of_vocab_words(ngram))\n",
        "        \n",
        "        probability_list = [self.model[ngram] for ngram in known_ngrams_list]\n",
        "        \n",
        "        perplexity = math.exp( (-1/num_test_word_tokens)* sum(map(math.log, probability_list)) )\n",
        "        return perplexity\n",
        "\n",
        "\n",
        "    def generate_sentence(self, min_length=10, max_length=20, given_incomplete_sentence = \"\"):\n",
        "        \"\"\"\n",
        "        Completes an incomplete sentence within a window of a minimum length and maximum length\n",
        "        \"\"\"\n",
        "        \n",
        "        def select_best_candidate(prev, exclude=[]):\n",
        "            \"\"\"\n",
        "            This utility function chooses the most probable next token given the previous (n-1) tokens.\n",
        "            \"\"\"\n",
        "            unwanted = [UNK_TOKEN] + exclude\n",
        "            candidates = [(ngram[-1], p) for ngram, p in self.model.items() if ngram[:-1] == prev]\n",
        "            desired_candidates = [cand for cand in candidates if cand[0] not in unwanted]\n",
        "            desired_candidates.sort(key=lambda c:c[1], reverse=True)\n",
        "            if (len(desired_candidates) == 0):\n",
        "                return (EOS_TOKEN, 1)\n",
        "            else:\n",
        "                # return the best candidate\n",
        "                return desired_candidates[0]\n",
        "    \n",
        "        sentence = []\n",
        "        probability = 1\n",
        "        if self.n == 1:\n",
        "            sentence = [\"<s>\"]\n",
        "        else:\n",
        "            sentence = [\"<s>\"] * (self.n - 1)\n",
        "\n",
        "        # assuming incomplete sentence is in correct format\n",
        "        for word in given_incomplete_sentence.split():\n",
        "            sentence.append(word.lower())\n",
        "\n",
        "        while (sentence[-1] != EOS_TOKEN):\n",
        "            prev = tuple()\n",
        "            if self.n != 1:\n",
        "                prev = tuple(sentence[-(self.n-1):])\n",
        "            \n",
        "            unwanted = []\n",
        "            if len(sentence) < min_length:\n",
        "                unwanted = sentence + [EOS_TOKEN]\n",
        "            \n",
        "            word, p = select_best_candidate(prev, exclude = unwanted)\n",
        "            sentence.append(word)\n",
        "            probability *= p\n",
        "\n",
        "            if len(sentence) >= max_length:\n",
        "                sentence.append(EOS_TOKEN)\n",
        "\n",
        "        resulting_sentence = \" \".join(sentence)\n",
        "\n",
        "        if probability == 1:\n",
        "            return resulting_sentence, probability\n",
        "\n",
        "        return resulting_sentence, -1/math.log(probability)"
      ],
      "metadata": {
        "id": "TbFwgeTPYjlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Generates a bitmask of 5 bits (testing to see if it is correct or not)\n",
        "# list(reversed(list(product((0,1), repeat=5))))"
      ],
      "metadata": {
        "id": "gBgqLcV-fZAb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test the model"
      ],
      "metadata": {
        "id": "Eo9lpQwSr_6I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams = {\n",
        "    \"n\": 1,\n",
        "    \"laplace\": 0.01,\n",
        "}"
      ],
      "metadata": {
        "id": "9XY9-FEYrSVi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Unigram"
      ],
      "metadata": {
        "id": "cS2RfDEZrPLT"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams[\"n\"] = 1\n",
        "\n",
        "model = NGramLanguageModel(\n",
        "    train_data=train_data, \n",
        "    n=hyperparams[\"n\"],\n",
        "    laplace=hyperparams[\"laplace\"],\n",
        ")\n",
        "print(\"Vocabulary size: {}\".format(len(model.vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-1YT-zXRtcG7",
        "outputId": "1c45454e-682d-4514-a49d-af62193e4bfc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 23505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = model.calculate_perplexity(test_data=test_data)\n",
        "print(\"Test set perplexity: {:.3f}\".format(perplexity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhnh8W_0tW7w",
        "outputId": "71f1adc7-25a4-4444-dd9e-05097e159510"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set perplexity: 762.939\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence, p = model.generate_sentence(10, 20, \"the company\")\n",
        "print(f\"Generated Sentence: {sentence}\")\n",
        "print(f\"probability: {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aDEk8p7jaa5D",
        "outputId": "236eb0e8-6d45-4bc1-bf79-3ece2666480f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: <s> the company of to in and said a mln the the the the the the the the the the </s>\n",
            "probability: 0.017014244038644752\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Bigram"
      ],
      "metadata": {
        "id": "L4z0fre2r3IQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams[\"n\"] = 2\n",
        "\n",
        "model = NGramLanguageModel(\n",
        "    train_data=train_data, \n",
        "    n=hyperparams[\"n\"],\n",
        "    laplace=hyperparams[\"laplace\"],\n",
        ")\n",
        "print(\"Vocabulary size: {}\".format(len(model.vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5bb348c3-bf09-45ef-a10d-2ec69ba801c2",
        "id": "8MzsioXrr3IQ"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 23505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = model.calculate_perplexity(test_data=test_data)\n",
        "print(\"Test set perplexity: {:.3f}\".format(perplexity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e785f8b4-8de6-4c46-fc6a-57794e524613",
        "id": "w3wYWDrHr3IS"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set perplexity: 85.795\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence, p = model.generate_sentence(10, 20, \"the company\")\n",
        "print(f\"Generated Sentence: {sentence}\")\n",
        "print(f\"probability: {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f200b9ef-37c2-41cc-b807-0bc695b7bc74",
        "id": "Z0AvfnsQr3IU"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: <s> the company said it has been made a share </s>\n",
            "probability: 0.052618529404116515\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Trigram"
      ],
      "metadata": {
        "id": "eIVrn5uar51a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams[\"n\"] = 3\n",
        "\n",
        "model = NGramLanguageModel(\n",
        "    train_data=train_data, \n",
        "    n=hyperparams[\"n\"],\n",
        "    laplace=hyperparams[\"laplace\"],\n",
        ")\n",
        "print(\"Vocabulary size: {}\".format(len(model.vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "528235a9-2e38-4a7c-e8bc-25c21662ba37",
        "id": "5CXk_2aOr51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 23505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = model.calculate_perplexity(test_data=test_data)\n",
        "print(\"Test set perplexity: {:.3f}\".format(perplexity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fe0a7a8-d66a-45af-cb35-76d720a71450",
        "id": "v-KZ5Ms-r51e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set perplexity: 51.555\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence, p = model.generate_sentence(10, 20, \"the company\")\n",
        "print(f\"Generated Sentence: {sentence}\")\n",
        "print(f\"probability: {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2c5122e2-f470-4702-e6c1-9772aec72f16",
        "id": "w2VT1ThNr51f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: <s> <s> the company said it has agreed to sell its shares in the first quarter of 1986 </s>\n",
            "probability: 0.02913691081782431\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4-gram"
      ],
      "metadata": {
        "id": "KNoC45xb69z4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "hyperparams[\"n\"] = 4\n",
        "\n",
        "model = NGramLanguageModel(\n",
        "    train_data=train_data, \n",
        "    n=hyperparams[\"n\"],\n",
        "    laplace=hyperparams[\"laplace\"],\n",
        ")\n",
        "print(\"Vocabulary size: {}\".format(len(model.vocab)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fcbf04e-2363-4ad8-85c0-7edb4c2892e6",
        "id": "aVl0zegS7C7X"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 23505\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "perplexity = model.calculate_perplexity(test_data=test_data)\n",
        "print(\"Test set perplexity: {:.3f}\".format(perplexity))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d6266d5e-12fc-4207-be4d-b6007ab8553f",
        "id": "TSvyXE3s7C7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test set perplexity: 40.549\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sentence, p = model.generate_sentence(10, 20, \"the company\")\n",
        "print(f\"Generated Sentence: {sentence}\")\n",
        "print(f\"probability: {p}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6043283e-4b5d-41a0-dcca-49b2670ea240",
        "id": "hZJEV2rU7C7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generated Sentence: <s> <s> <s> the company said it will offer a stake in the company </s>\n",
            "probability: 0.03218777588375814\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8ZqyeJYJqDmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}